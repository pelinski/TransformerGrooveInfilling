{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append('../model')\n",
    "sys.path.append('../../preprocessed_dataset/')\n",
    "import math\n",
    "\n",
    "from dataset_loader import GrooveMidiDataset\n",
    "from Subset_Creators.subsetters import GrooveMidiSubsetter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(torch.nn.Module):\n",
    "    r\"\"\"Inject some information about the relative or absolute position of the tokens\n",
    "        in the sequence. The positional encodings have the same dimension as\n",
    "        the embeddings, so that the two can be summed. Here, we use sine and cosine\n",
    "        functions of different frequencies.\n",
    "    .. math::\n",
    "        \\text{PosEncoder}(pos, 2i) = sin(pos/10000^(2i/d_model))\n",
    "        \\text{PosEncoder}(pos, 2i+1) = cos(pos/10000^(2i/d_model))\n",
    "        \\text{where pos is the word position and i is the embed idx)\n",
    "    Args:\n",
    "        d_model: the embed dim (required).\n",
    "        dropout: the dropout value (default=0.1).\n",
    "        max_len: the max. length of the incoming sequence (default=5000).\n",
    "    Examples:\n",
    "        >>> pos_encoder = PositionalEncoding(d_model)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "        \n",
    "        pe = torch.zeros(max_len, d_model) # shape (max_len=5000, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float) # Shape (max_len=5000)\n",
    "        position = position.unsqueeze(1) # Shape (5000, 1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)) # Shape (d_model/2)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term) \n",
    "        if d_model % 2 is not 0:\n",
    "            pe[:, 1::2] = torch.cos(position * div_term)[:,:-1]\n",
    "        else: \n",
    "            pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        # Insert a new dimension for batch size\n",
    "        pe = pe.unsqueeze(0) # Shape (1, 5000, d_model)\n",
    "        pe = pe.transpose(0, 1) # Shape (5000, 1, d_model) \n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        r\"\"\"Inputs of forward function\n",
    "        Args:\n",
    "            x: the sequence fed to the positional encoder model (required).\n",
    "        Shape:\n",
    "            x: [sequence length, batch size, embed dim]\n",
    "            output: [sequence length, batch size, embed dim]\n",
    "        Examples:\n",
    "            >>> output = pos_encoder(x)\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer (torch.nn.Module):\n",
    "    def __init__(self, d_model_enc, d_model_dec, nhead_enc,nhead_dec, dim_feedforward, dropout, num_encoder_layers, num_decoder_layers,max_len):\n",
    "        super(Transformer,self).__init__()\n",
    "        \n",
    "        self.PositionalEncoder = PositionalEncoding(d_model_enc, dropout, max_len)\n",
    "        \n",
    "        norm_encoder = torch.nn.LayerNorm(d_model_enc)\n",
    "        encoder_layer = torch.nn.TransformerEncoderLayer(d_model_enc, nhead_enc, dim_feedforward,dropout)\n",
    "        self.Encoder = torch.nn.TransformerEncoder(encoder_layer, num_encoder_layers, norm_encoder)\n",
    "        \n",
    "        self.MemoryMap = torch.nn.Linear(d_model_enc, d_model_dec, bias=False)\n",
    "        \n",
    "        norm_decoder = torch.nn.LayerNorm(d_model_dec)\n",
    "        decoder_layer = torch.nn.TransformerDecoderLayer(d_model_dec, nhead_dec, dim_feedforward, dropout)\n",
    "        self.Decoder = torch.nn.TransformerDecoder(decoder_layer, num_decoder_layers, norm_decoder)\n",
    "        \n",
    "        \n",
    "    def forward(self, src=None, tgt=None, _mem=None, only_encoder=False, only_decoder=False):\n",
    "        \n",
    "        x = self.PositionalEncoder(src)\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        if only_encoder:\n",
    "            memory = self.Encoder(x)\n",
    "            return memory\n",
    "        \n",
    "        if only_decoder: \n",
    "            mask = (torch.triu(torch.ones(tgt.shape[0], tgt.shape[0])) == 1)             # future mask\n",
    "            out = self.Decoder(tgt,_mem, tgt_mask=mask)\n",
    "            out = torch.reshape(out, (tgt_len, N, 3, d_model // 3))\n",
    "            return out\n",
    "        \n",
    "        \"\"\"\n",
    "        memory = self.Encoder(x)\n",
    "        memory_map = self.MemoryMap(memory)\n",
    "        \n",
    "        mask = (torch.triu(torch.ones(tgt.shape[0], tgt.shape[0])) == 1).transpose(0, 1).float()\n",
    "        mask = mask.masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "\n",
    "        out = self.Decoder(tgt, memory_map, tgt_mask=mask)\n",
    "        out = torch.reshape(out, (tgt.shape[0], tgt.shape[1], 3, d_model_dec // 3))\n",
    "        \n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x torch.Size([12, 24, 27])\n",
      "memory torch.Size([12, 24, 27])\n",
      "memory_map torch.Size([12, 24, 27])\n",
      "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "maskshape torch.Size([12, 12])\n",
      "tensor([[[-0.0525,  1.8581, -1.4336,  ...,  1.0976,  1.9997, -0.1828],\n",
      "         [-1.2382,  0.3694,  1.3394,  ..., -0.2251,  0.5634, -0.3496],\n",
      "         [-2.0220, -1.5778,  1.0643,  ..., -0.3008, -0.0945, -0.7335],\n",
      "         ...,\n",
      "         [-0.4281,  0.1321,  1.6892,  ..., -0.3588,  0.7192, -0.7215],\n",
      "         [-1.6692, -1.4912,  0.7102,  ..., -0.9023,  0.0487, -0.1709],\n",
      "         [-1.4426, -0.8206,  1.0818,  ..., -0.4013, -1.1940, -1.0818]],\n",
      "\n",
      "        [[-0.6688,  0.7078, -1.0988,  ...,  0.8831,  1.3903, -0.9047],\n",
      "         [-0.8754, -0.6026,  0.8035,  ...,  0.8241,  0.6464, -0.7755],\n",
      "         [-0.9148, -2.2633,  0.7308,  ..., -0.0345, -0.4608, -0.1875],\n",
      "         ...,\n",
      "         [-0.4020,  0.3802,  0.6572,  ..., -0.3402,  0.9271, -0.3299],\n",
      "         [-1.3241, -1.4369,  0.8886,  ..., -0.8984,  0.3788, -0.3893],\n",
      "         [ 0.8635,  1.5858, -0.5555,  ...,  0.4926,  0.2284, -0.1314]],\n",
      "\n",
      "        [[ 0.0763,  0.5487, -0.5858,  ...,  0.7771,  1.1534,  0.6112],\n",
      "         [-1.2119, -0.1317,  1.3315,  ..., -0.2405, -0.0172, -0.1841],\n",
      "         [-1.2953, -0.7168,  1.5010,  ...,  0.3775, -0.4624, -0.2102],\n",
      "         ...,\n",
      "         [-1.0202,  0.1243,  1.3852,  ...,  0.5308, -0.2933, -0.2165],\n",
      "         [-1.9292, -1.2662,  0.7249,  ..., -0.5994, -0.0561, -0.0206],\n",
      "         [-0.5347,  0.9960,  0.1272,  ..., -0.1509,  1.1359, -0.0809]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.3115,  0.2139,  0.7308,  ...,  0.4726,  0.7392, -0.7257],\n",
      "         [-1.1974,  0.9737,  1.0046,  ..., -0.1354, -0.0163, -0.3072],\n",
      "         [-1.2811, -0.7900,  1.3121,  ..., -0.1560, -0.3906, -0.2568],\n",
      "         ...,\n",
      "         [ 0.1686,  0.3717,  0.8359,  ...,  1.0179,  0.7453, -0.3081],\n",
      "         [-1.6761, -0.4210,  0.8173,  ..., -0.0130,  0.7232, -0.5755],\n",
      "         [-1.5614, -0.4117,  0.6178,  ..., -0.0551,  0.4938, -0.4156]],\n",
      "\n",
      "        [[-0.8328,  0.0928,  1.1128,  ...,  0.6343,  0.5682, -0.7927],\n",
      "         [-1.1567,  0.4104,  0.5873,  ..., -0.1799,  0.5328, -0.1174],\n",
      "         [-1.1389, -0.6532,  0.7939,  ..., -0.6860, -0.3734, -0.1876],\n",
      "         ...,\n",
      "         [-0.9060, -0.3816,  1.3195,  ...,  0.4399,  0.2173,  0.5504],\n",
      "         [-0.9379, -1.4635,  1.2084,  ..., -0.4173,  0.8099,  0.5985],\n",
      "         [-0.3638, -0.0278,  0.7446,  ...,  0.0605,  0.7992, -0.5816]],\n",
      "\n",
      "        [[-1.0296, -0.4351,  0.0599,  ...,  0.5009,  1.0960, -0.3373],\n",
      "         [-0.2798, -0.0359,  1.1306,  ..., -0.1059,  0.1904, -0.3060],\n",
      "         [-1.1735, -1.9036,  0.4742,  ..., -0.0817,  0.6609,  0.4547],\n",
      "         ...,\n",
      "         [ 0.0526,  0.5986,  1.6752,  ...,  0.2393, -0.3700, -0.2718],\n",
      "         [-0.1766, -0.6785,  0.9251,  ...,  0.5029,  0.8852, -0.5730],\n",
      "         [-0.9600,  0.4657, -0.2599,  ...,  0.6037,  0.7379, -0.6443]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "out torch.Size([12, 24, 27])\n",
      "torch.Size([12, 24, 3, 9])\n"
     ]
    }
   ],
   "source": [
    "d_model_enc = 27\n",
    "d_model_dec = 27\n",
    "nhead_enc = 3\n",
    "nhead_dec = 3\n",
    "dim_feedforward = d_model*10\n",
    "dropout = 0.1\n",
    "num_encoder_layers = 5\n",
    "num_decoder_layers = 6\n",
    "max_len=32\n",
    "\n",
    "\n",
    "\n",
    "TM = Transformer(d_model_enc,d_model_dec, nhead_enc, nhead_dec, dim_feedforward, dropout, num_encoder_layers, num_decoder_layers,max_len)\n",
    "\n",
    "N = 24\n",
    "src_len = 12\n",
    "tgt_len = 12\n",
    "\n",
    "src = torch.rand(src_len, N, d_model_enc)\n",
    "tgt = torch.rand(tgt_len, N, d_model_dec)\n",
    "\n",
    "print(TM.forward(src,tgt).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test gmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = {\"beat_type\": [\"beat\"],\n",
    "           \"time_signature\" : [\"4-4\"],\n",
    "           \"master_id\":[\"drummer9/session1/9\"]}\n",
    "\n",
    "mso_parameters = {\"sr\": 44100,\n",
    "                  \"n_fft\": 1024,\n",
    "                  \"win_length\": 1024,\n",
    "                  \"hop_length\": 441,\n",
    "                  \"n_bins_per_octave\": 16,\n",
    "                  \"n_octaves\": 9,\n",
    "                  \"f_min\": 40,\n",
    "                  \"mean_filter_size\": 22\n",
    "                 }\n",
    "\n",
    "voices_parameters = {\"voice_idx\": [2], # closed hihat\n",
    "                     \"min_n_voices_to_remove\": 1,\n",
    "                     \"max_n_voices_to_remove\": 1,\n",
    "                     \"prob\": [1],\n",
    "                     \"k\": 1}\n",
    "\n",
    "\n",
    "# train subset\n",
    "pickle_source_path = '../../preprocessed_dataset/datasets_extracted_locally/GrooveMidi/hvo_0.4.2/Processed_On_17_05_2021_at_22_32_hrs'\n",
    "subset_name = 'GrooveMIDI_processed_train'\n",
    "metadata_csv_filename = 'metadata.csv'\n",
    "hvo_pickle_filename = 'hvo_sequence_data.obj'\n",
    "\n",
    "gmd_subsetter = GrooveMidiSubsetter(\n",
    "    pickle_source_path=pickle_source_path,\n",
    "    subset=subset_name,\n",
    "    hvo_pickle_filename=hvo_pickle_filename,\n",
    "    list_of_filter_dicts_for_subsets=[filters],\n",
    ")\n",
    "_, subset_list = gmd_subsetter.create_subsets()\n",
    "\n",
    "subset_info = {\"pickle_source_path\": pickle_source_path,\n",
    "               \"subset\": subset_name,\n",
    "               \"metadata_csv_filename\": metadata_csv_filename,\n",
    "               \"hvo_pickle_filename\": hvo_pickle_filename,\n",
    "               \"filters\": filters}\n",
    "\n",
    "\n",
    "train_data = GrooveMidiDataset(subset=subset_list[0], subset_info=subset_info, mso_parameters=mso_parameters,\n",
    "                                     max_aug_items=100, voices_parameters=voices_parameters)\n",
    "\n",
    "# test \n",
    "pickle_source_path = '../../preprocessed_dataset/datasets_extracted_locally/GrooveMidi/hvo_0.4.2/Processed_On_17_05_2021_at_22_32_hrs'\n",
    "subset_name = 'GrooveMIDI_processed_test'\n",
    "metadata_csv_filename = 'metadata.csv'\n",
    "hvo_pickle_filename = 'hvo_sequence_data.obj'\n",
    "\n",
    "filters = {\"beat_type\": [\"beat\"],\n",
    "           \"time_signature\" : [\"4-4\"],\n",
    "           \"master_id\":[\"drummer9/session1/7\"]}\n",
    "\n",
    "\n",
    "gmd_subsetter = GrooveMidiSubsetter(\n",
    "    pickle_source_path=pickle_source_path,\n",
    "    subset=subset_name,\n",
    "    hvo_pickle_filename=hvo_pickle_filename,\n",
    "    list_of_filter_dicts_for_subsets=[filters],\n",
    ")\n",
    "_, subset_list = gmd_subsetter.create_subsets()\n",
    "\n",
    "subset_info = {\"pickle_source_path\": pickle_source_path,\n",
    "               \"subset\": subset_name,\n",
    "               \"metadata_csv_filename\": metadata_csv_filename,\n",
    "               \"hvo_pickle_filename\": hvo_pickle_filename,\n",
    "               \"filters\": filters}\n",
    "\n",
    "\n",
    "test_data = GrooveMidiDataset(subset=subset_list[0], subset_info=subset_info, mso_parameters=mso_parameters,\n",
    "                                    max_aug_items=100, voices_parameters=voices_parameters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\n",
    "\n",
    "\n",
    "d_model_enc = 16\n",
    "d_model_dec = 27\n",
    "nhead_enc = 4\n",
    "nhead_dec = 3\n",
    "dim_feedforward = d_model*10\n",
    "dropout = 0.1\n",
    "num_encoder_layers = 5\n",
    "num_decoder_layers = 6\n",
    "max_len=32\n",
    "\n",
    "\n",
    "\n",
    "TM = Transformer(d_model_enc,d_model_dec, nhead_enc, nhead_dec, dim_feedforward, dropout, num_encoder_layers, num_decoder_layers,max_len)\n",
    "\n",
    "\n",
    "\n",
    "model = TM.to(device)\n",
    "\n",
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)    \n",
    "    for batch, (X,y,idx) in enumerate(dataloader):\n",
    "        X = X.reshape((32,64,16)) # reorder dimensions\n",
    "        y = y.reshape((32,64,27)) # reorder dimensions\n",
    "        \n",
    "        # Compute prediction and loss\n",
    "        y_s = torch.zeros([1,64,27])\n",
    "        y_s = torch.cat((y_s, y), dim=0)\n",
    "\n",
    "        pred = model(X,y_s)\n",
    "        y_s = y_s.reshape((y_s.shape[0], y_s.shape[1], 3, d_model_dec // 3))\n",
    "        \n",
    "        h = pred[:,1,0,:]\n",
    "        print(h)\n",
    "\n",
    "        \n",
    "        print(pred.shape, y_s.shape)\n",
    "        \n",
    "        #print(pred.shape, y.shape)\n",
    "        #pred_l = pred.reshape([64,33,27])\n",
    "        #y_l = y.reshape([64,32,27])\n",
    "        \n",
    "        # TODO sum 3 different losses\n",
    "        loss = loss_fn(pred_l, y_l)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            \n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y, idx in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "x torch.Size([32, 64, 16])\n",
      "memory torch.Size([32, 64, 16])\n",
      "memory_map torch.Size([32, 64, 27])\n",
      "mask torch.Size([33, 33])\n",
      "tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan]], grad_fn=<SliceBackward>)\n",
      "out torch.Size([33, 64, 27])\n",
      "tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "       grad_fn=<SliceBackward>)\n",
      "torch.Size([33, 64, 3, 9]) torch.Size([33, 64, 3, 9])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pred_l' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-317-6e6794d39e69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {t+1}\\n-------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtest_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-316-9411befd9ee5>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# TODO sum 3 different losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_l\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# Backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pred_l' is not defined"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_thesis",
   "language": "python",
   "name": "torch_thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from hvo_sequence.hvo_seq import HVO_Sequence\n",
    "from hvo_sequence.drum_mappings import ROLAND_REDUCED_MAPPING\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n"
   ]
  },
  {
   "source": [
    "### Load processed dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "processed_dataset/Processed_On_27_04_2021_at_19_04_hrs/GrooveMIDI_processed_train/hvo_data.obj\n",
      "Dataset Size: 17108 \n",
      " Features:  ['Unnamed: 0', 'drummer', 'session', 'loop_id', 'master_id', 'style_primary', 'style_secondary', 'bpm', 'beat_type', 'time_signature', 'full_midi_filename', 'full_audio_filename']\n"
     ]
    }
   ],
   "source": [
    "source_path = \"processed_dataset/Processed_On_27_04_2021_at_19_04_hrs\"\n",
    "print(os.path.join(source_path, \"GrooveMIDI_processed_train\", \"hvo_data.obj\"))\n",
    "train_file = open(os.path.join(source_path, \"GrooveMIDI_processed_train\", \"hvo_sequence_data.obj\"),'rb')\n",
    "train_set = pickle.load(train_file)\n",
    "metadata = pd.read_csv(os.path.join(source_path, \"GrooveMIDI_processed_train\", \"metadata.csv\"))\n",
    "\n",
    "features_in_metadata = list(metadata.columns)\n",
    "\n",
    "dataset_size = len(train_set)\n",
    "\n",
    "print(\"Dataset Size: %d \\n Features: \" % dataset_size, features_in_metadata)"
   ]
  },
  {
   "source": [
    "### Select random example"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sample Number: 12172, Primary Style: None, Secondary Style: hiphop\n"
     ]
    }
   ],
   "source": [
    "ix =  int(np.random.random_sample()*dataset_size)\n",
    "print(\"Sample Number: %d, Primary Style: %s, Secondary Style: %s\" % (ix, \n",
    "                                                                     metadata[\"style_secondary\"][ix], \n",
    "                                                                     metadata[\"style_primary\"][ix])\n",
    "     )\n",
    "\n",
    "example = train_set[ix]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mel_spec = example.mel_spectrogram(sf_path=\"hvo_sequence/soundfonts/Standard_Drum_Kit.sf2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import show\n",
    "\n",
    "fig = train_set[ix].to_html_plot(filename=\"onsets_and_intensity/misc/temp.html\")\n",
    "show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_thesis",
   "language": "python",
   "name": "torch_thesis"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}